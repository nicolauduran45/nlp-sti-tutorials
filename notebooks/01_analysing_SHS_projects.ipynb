{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Analysing SHS Projects\n",
    "\n",
    "In this tutorial, we will work step by step to analyze research projects and classify whether they belong to **Social Sciences and Humanities (SHS)**.  \n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Data Gathering\n",
    "\n",
    "We will collect datasets from three main sources:  \n",
    "\n",
    "1. **ANR Projects (France)**  \n",
    "   - Source: [data.gouv.fr](https://www.data.gouv.fr/api/1/datasets/r/74a59cc0-ef79-458a-83e0-f181f9da459f)  \n",
    "\n",
    "2. **CORDIS Horizon Projects (EU)**  \n",
    "   - Source: [CORDIS Portal](https://cordis.europa.eu/data/cordis-HORIZONprojects-csv.zip)  \n",
    "\n",
    "3. **Irish Research Council (IRC)**  \n",
    "   - Source: [research.ie](https://research.ie/awardees_search/download.php?file=irc-awardees-search--.csv)  \n",
    "\n",
    "We will store the raw files under:  \n",
    "\n",
    "```\n",
    "data/analysing_SHS_projects/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setup\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "# Create data folder\n",
    "data_dir = \"../data/analysing_SHS_projects\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download ANR Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANR shape: (6478, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Projet.Code_Decision_ANR</th>\n",
       "      <th>AAP.Edition</th>\n",
       "      <th>Projet.Acronyme</th>\n",
       "      <th>Projet.Titre.Francais</th>\n",
       "      <th>Projet.Titre.Anglais</th>\n",
       "      <th>Projet.Resume.Francais</th>\n",
       "      <th>Projet.Resume.Anglais</th>\n",
       "      <th>Programme.Acronyme</th>\n",
       "      <th>Projet.Montant.AF.Aide_allouee.ANR</th>\n",
       "      <th>Projet.T0 scientifique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANR-09-VPTT-0015</td>\n",
       "      <td>2009</td>\n",
       "      <td>ATAC-CONCEPT</td>\n",
       "      <td>Convertisseur auxiliaire avancé à refroidissem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L’objectif du Projet ATAC-CONCEPT est de dével...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VTT</td>\n",
       "      <td>481373.0</td>\n",
       "      <td>2009-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANR-09-VPTT-0014</td>\n",
       "      <td>2009</td>\n",
       "      <td>VOLHAND</td>\n",
       "      <td>VOLant pour personne âgée et/ou HANDicapée : D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A ce jour, il n’existe pas de système de direc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VTT</td>\n",
       "      <td>959412.0</td>\n",
       "      <td>2009-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANR-09-VPTT-0013</td>\n",
       "      <td>2009</td>\n",
       "      <td>TAYLRUB</td>\n",
       "      <td>Gérer les compromis de propriétés des caoutcho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Les silices précipitées sont utilisées comme c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VTT</td>\n",
       "      <td>490545.0</td>\n",
       "      <td>2009-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANR-09-VPTT-0012</td>\n",
       "      <td>2009</td>\n",
       "      <td>SYNERGIE</td>\n",
       "      <td>SYstème d'admission Novateur pour des Emission...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Les transports terrestres et en particulier au...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VTT</td>\n",
       "      <td>1574420.0</td>\n",
       "      <td>2009-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANR-09-VPTT-0011</td>\n",
       "      <td>2009</td>\n",
       "      <td>SPEEDCAM</td>\n",
       "      <td>Détermination de la Limitation de Vitesse par ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afin d'assurer une sécurité maximale sur les r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VTT</td>\n",
       "      <td>672464.0</td>\n",
       "      <td>2009-10-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Projet.Code_Decision_ANR  AAP.Edition Projet.Acronyme  \\\n",
       "0         ANR-09-VPTT-0015         2009    ATAC-CONCEPT   \n",
       "1         ANR-09-VPTT-0014         2009         VOLHAND   \n",
       "2         ANR-09-VPTT-0013         2009         TAYLRUB   \n",
       "3         ANR-09-VPTT-0012         2009        SYNERGIE   \n",
       "4         ANR-09-VPTT-0011         2009        SPEEDCAM   \n",
       "\n",
       "                               Projet.Titre.Francais Projet.Titre.Anglais  \\\n",
       "0  Convertisseur auxiliaire avancé à refroidissem...                  NaN   \n",
       "1  VOLant pour personne âgée et/ou HANDicapée : D...                  NaN   \n",
       "2  Gérer les compromis de propriétés des caoutcho...                  NaN   \n",
       "3  SYstème d'admission Novateur pour des Emission...                  NaN   \n",
       "4  Détermination de la Limitation de Vitesse par ...                  NaN   \n",
       "\n",
       "                              Projet.Resume.Francais Projet.Resume.Anglais  \\\n",
       "0  L’objectif du Projet ATAC-CONCEPT est de dével...                   NaN   \n",
       "1  A ce jour, il n’existe pas de système de direc...                   NaN   \n",
       "2  Les silices précipitées sont utilisées comme c...                   NaN   \n",
       "3  Les transports terrestres et en particulier au...                   NaN   \n",
       "4  Afin d'assurer une sécurité maximale sur les r...                   NaN   \n",
       "\n",
       "  Programme.Acronyme  Projet.Montant.AF.Aide_allouee.ANR  \\\n",
       "0                VTT                            481373.0   \n",
       "1                VTT                            959412.0   \n",
       "2                VTT                            490545.0   \n",
       "3                VTT                           1574420.0   \n",
       "4                VTT                            672464.0   \n",
       "\n",
       "  Projet.T0 scientifique  \n",
       "0             2009-12-01  \n",
       "1             2009-10-01  \n",
       "2             2009-10-01  \n",
       "3             2009-10-01  \n",
       "4             2009-10-01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anr_url = \"https://www.data.gouv.fr/api/1/datasets/r/74a59cc0-ef79-458a-83e0-f181f9da459f\"\n",
    "anr_path = os.path.join(data_dir, \"anr_projects.csv\")\n",
    "\n",
    "if not os.path.exists(anr_path):\n",
    "    r = requests.get(anr_url)\n",
    "    with open(anr_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "df_anr = pd.read_csv(anr_path, sep=\";\", low_memory=False)\n",
    "print(\"ANR shape:\", df_anr.shape)\n",
    "df_anr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download CORDIS Horizon Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORDIS shape: (18110, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acronym</th>\n",
       "      <th>status</th>\n",
       "      <th>title</th>\n",
       "      <th>startDate</th>\n",
       "      <th>endDate</th>\n",
       "      <th>totalCost</th>\n",
       "      <th>ecMaxContribution</th>\n",
       "      <th>legalBasis</th>\n",
       "      <th>topics</th>\n",
       "      <th>ecSignatureDate</th>\n",
       "      <th>frameworkProgramme</th>\n",
       "      <th>masterCall</th>\n",
       "      <th>subCall</th>\n",
       "      <th>fundingScheme</th>\n",
       "      <th>objective</th>\n",
       "      <th>contentUpdateDate</th>\n",
       "      <th>rcn</th>\n",
       "      <th>grantDoi</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101234994</td>\n",
       "      <td>OPTIMALMINE</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>OPTIMALMINE: slope optimal design for a paradi...</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>2029-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1072140</td>\n",
       "      <td>HORIZON.1.2</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01-01</td>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-TMA-MSCA-SE</td>\n",
       "      <td>The European Union is currently addressing cha...</td>\n",
       "      <td>2025-07-25 11:08:05</td>\n",
       "      <td>274682</td>\n",
       "      <td>10.3030/101234994</td>\n",
       "      <td>mine optimisation,  rock slope engineering,  o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101232577</td>\n",
       "      <td>HSAFE</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>Innovative high-sensitivity avalanche field-ef...</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>2029-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1618230</td>\n",
       "      <td>HORIZON.1.2</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01-01</td>\n",
       "      <td>2025-07-22</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-TMA-MSCA-SE</td>\n",
       "      <td>The focus of the HSAFE project, which aligns w...</td>\n",
       "      <td>2025-07-25 11:08:05</td>\n",
       "      <td>274696</td>\n",
       "      <td>10.3030/101232577</td>\n",
       "      <td>Field-effect transistor-based biosensors, Canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101236527</td>\n",
       "      <td>DRU</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>Democratic Roles of Universities (DRU): Practi...</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>2030-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1593180</td>\n",
       "      <td>HORIZON.1.2</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01-01</td>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-TMA-MSCA-SE</td>\n",
       "      <td>DRU’s objective is to find new ways that unive...</td>\n",
       "      <td>2025-07-25 11:08:04</td>\n",
       "      <td>274676</td>\n",
       "      <td>10.3030/101236527</td>\n",
       "      <td>Universities,  Citizen science,  Civic engagement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101236483</td>\n",
       "      <td>3D-TOPO</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>3D topological states in solid and soft ferroe...</td>\n",
       "      <td>2026-02-01</td>\n",
       "      <td>2030-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1117230</td>\n",
       "      <td>HORIZON.1.2</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01-01</td>\n",
       "      <td>2025-07-22</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-TMA-MSCA-SE</td>\n",
       "      <td>The 3D-TOPO project uncovers novel topological...</td>\n",
       "      <td>2025-07-25 11:08:06</td>\n",
       "      <td>274700</td>\n",
       "      <td>10.3030/101236483</td>\n",
       "      <td>Ferroelectrics, Liquid Crystals, Topological s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101235387</td>\n",
       "      <td>I-TEXGEO</td>\n",
       "      <td>SIGNED</td>\n",
       "      <td>IoT Supported Electronic Geotextiles for Susta...</td>\n",
       "      <td>2026-01-01</td>\n",
       "      <td>2029-12-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1683360</td>\n",
       "      <td>HORIZON.1.2</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01-01</td>\n",
       "      <td>2025-07-22</td>\n",
       "      <td>HORIZON</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-MSCA-2024-SE-01</td>\n",
       "      <td>HORIZON-TMA-MSCA-SE</td>\n",
       "      <td>This project aims to develop an innovative IoT...</td>\n",
       "      <td>2025-07-25 11:08:06</td>\n",
       "      <td>274694</td>\n",
       "      <td>10.3030/101235387</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      acronym  status  \\\n",
       "0  101234994  OPTIMALMINE  SIGNED   \n",
       "1  101232577        HSAFE  SIGNED   \n",
       "2  101236527          DRU  SIGNED   \n",
       "3  101236483      3D-TOPO  SIGNED   \n",
       "4  101235387     I-TEXGEO  SIGNED   \n",
       "\n",
       "                                               title   startDate     endDate  \\\n",
       "0  OPTIMALMINE: slope optimal design for a paradi...  2025-09-01  2029-08-31   \n",
       "1  Innovative high-sensitivity avalanche field-ef...  2025-09-01  2029-08-31   \n",
       "2  Democratic Roles of Universities (DRU): Practi...  2026-02-01  2030-01-31   \n",
       "3  3D topological states in solid and soft ferroe...  2026-02-01  2030-01-31   \n",
       "4  IoT Supported Electronic Geotextiles for Susta...  2026-01-01  2029-12-31   \n",
       "\n",
       "  totalCost ecMaxContribution   legalBasis                      topics  \\\n",
       "0         0           1072140  HORIZON.1.2  HORIZON-MSCA-2024-SE-01-01   \n",
       "1         0           1618230  HORIZON.1.2  HORIZON-MSCA-2024-SE-01-01   \n",
       "2         0           1593180  HORIZON.1.2  HORIZON-MSCA-2024-SE-01-01   \n",
       "3         0           1117230  HORIZON.1.2  HORIZON-MSCA-2024-SE-01-01   \n",
       "4         0           1683360  HORIZON.1.2  HORIZON-MSCA-2024-SE-01-01   \n",
       "\n",
       "  ecSignatureDate frameworkProgramme               masterCall  \\\n",
       "0      2025-07-10            HORIZON  HORIZON-MSCA-2024-SE-01   \n",
       "1      2025-07-22            HORIZON  HORIZON-MSCA-2024-SE-01   \n",
       "2      2025-07-10            HORIZON  HORIZON-MSCA-2024-SE-01   \n",
       "3      2025-07-22            HORIZON  HORIZON-MSCA-2024-SE-01   \n",
       "4      2025-07-22            HORIZON  HORIZON-MSCA-2024-SE-01   \n",
       "\n",
       "                   subCall        fundingScheme  \\\n",
       "0  HORIZON-MSCA-2024-SE-01  HORIZON-TMA-MSCA-SE   \n",
       "1  HORIZON-MSCA-2024-SE-01  HORIZON-TMA-MSCA-SE   \n",
       "2  HORIZON-MSCA-2024-SE-01  HORIZON-TMA-MSCA-SE   \n",
       "3  HORIZON-MSCA-2024-SE-01  HORIZON-TMA-MSCA-SE   \n",
       "4  HORIZON-MSCA-2024-SE-01  HORIZON-TMA-MSCA-SE   \n",
       "\n",
       "                                           objective    contentUpdateDate  \\\n",
       "0  The European Union is currently addressing cha...  2025-07-25 11:08:05   \n",
       "1  The focus of the HSAFE project, which aligns w...  2025-07-25 11:08:05   \n",
       "2  DRU’s objective is to find new ways that unive...  2025-07-25 11:08:04   \n",
       "3  The 3D-TOPO project uncovers novel topological...  2025-07-25 11:08:06   \n",
       "4  This project aims to develop an innovative IoT...  2025-07-25 11:08:06   \n",
       "\n",
       "      rcn           grantDoi  \\\n",
       "0  274682  10.3030/101234994   \n",
       "1  274696  10.3030/101232577   \n",
       "2  274676  10.3030/101236527   \n",
       "3  274700  10.3030/101236483   \n",
       "4  274694  10.3030/101235387   \n",
       "\n",
       "                                            keywords  \n",
       "0  mine optimisation,  rock slope engineering,  o...  \n",
       "1  Field-effect transistor-based biosensors, Canc...  \n",
       "2  Universities,  Citizen science,  Civic engagement  \n",
       "3  Ferroelectrics, Liquid Crystals, Topological s...  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cordis_url = \"https://cordis.europa.eu/data/cordis-HORIZONprojects-csv.zip\"\n",
    "cordis_zip = os.path.join(data_dir, \"cordis_projects.zip\")\n",
    "cordis_path = os.path.join(data_dir, \"project.csv\")\n",
    "\n",
    "if not os.path.exists(cordis_path):\n",
    "    r = requests.get(cordis_url)\n",
    "    with open(cordis_zip, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "    with zipfile.ZipFile(cordis_zip, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "\n",
    "# The extracted file has a long name, detect it\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.startswith(\"projects\") and file.endswith(\".csv\"):\n",
    "        cordis_path = os.path.join(data_dir, file)\n",
    "\n",
    "df_cordis = pd.read_csv(cordis_path, low_memory=False, on_bad_lines=\"skip\", sep=\";\")\n",
    "print(\"CORDIS shape:\", df_cordis.shape)\n",
    "df_cordis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Exploration & Cleaning\n",
    "\n",
    "We now have two datasets:  \n",
    "- **ANR Projects** (French National Research Agency)  \n",
    "- **CORDIS Projects** (EU Horizon)  \n",
    "\n",
    "The schemas are different, so we will:  \n",
    "1. Inspect the columns  \n",
    "2. Select comparable fields (id, title, abstract)  \n",
    "3. Harmonize them into a single dataset  \n",
    "4. Add a `source` column  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANR columns: ['Projet.Code_Decision_ANR', 'AAP.Edition', 'Projet.Acronyme', 'Projet.Titre.Francais', 'Projet.Titre.Anglais', 'Projet.Resume.Francais', 'Projet.Resume.Anglais', 'Programme.Acronyme', 'Projet.Montant.AF.Aide_allouee.ANR', 'Projet.T0 scientifique']\n",
      "CORDIS columns: ['id', 'acronym', 'status', 'title', 'startDate', 'endDate', 'totalCost', 'ecMaxContribution', 'legalBasis', 'topics', 'ecSignatureDate', 'frameworkProgramme', 'masterCall', 'subCall', 'fundingScheme', 'objective', 'contentUpdateDate', 'rcn', 'grantDoi', 'keywords']\n",
      "ANR clean shape: (6478, 4)\n",
      "CORDIS clean shape: (18110, 4)\n",
      "Merged shape: (24588, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10304</th>\n",
       "      <td>101080164</td>\n",
       "      <td>Deep Ultraviolet Laser For Quantum Technology</td>\n",
       "      <td>Lasers are the heart of today’s quantum scienc...</td>\n",
       "      <td>cordis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15085</th>\n",
       "      <td>101188025</td>\n",
       "      <td>An Application for leveraging large-scale hist...</td>\n",
       "      <td>HistText is a groundbreaking application devel...</td>\n",
       "      <td>cordis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13009</th>\n",
       "      <td>101158232</td>\n",
       "      <td>Universal Data Compression with Circular Conte...</td>\n",
       "      <td>Within the ITUL project, funded by an ERC Cons...</td>\n",
       "      <td>cordis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10090</th>\n",
       "      <td>101052653</td>\n",
       "      <td>Why late earliest occupation of Western Europe ?</td>\n",
       "      <td>The project aims to question human migrations ...</td>\n",
       "      <td>cordis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20812</th>\n",
       "      <td>101087829</td>\n",
       "      <td>Straintronic control of correlations in twiste...</td>\n",
       "      <td>Correlations and topology are the cornerstones...</td>\n",
       "      <td>cordis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      project_id                                              title  \\\n",
       "10304  101080164      Deep Ultraviolet Laser For Quantum Technology   \n",
       "15085  101188025  An Application for leveraging large-scale hist...   \n",
       "13009  101158232  Universal Data Compression with Circular Conte...   \n",
       "10090  101052653   Why late earliest occupation of Western Europe ?   \n",
       "20812  101087829  Straintronic control of correlations in twiste...   \n",
       "\n",
       "                                                abstract  source  \n",
       "10304  Lasers are the heart of today’s quantum scienc...  cordis  \n",
       "15085  HistText is a groundbreaking application devel...  cordis  \n",
       "13009  Within the ITUL project, funded by an ERC Cons...  cordis  \n",
       "10090  The project aims to question human migrations ...  cordis  \n",
       "20812  Correlations and topology are the cornerstones...  cordis  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect first few columns\n",
    "print(\"ANR columns:\", df_anr.columns.tolist())\n",
    "print(\"CORDIS columns:\", df_cordis.columns.tolist())\n",
    "\n",
    "# Select & rename relevant columns for ANR\n",
    "df_anr_clean = df_anr.rename(\n",
    "    columns={\n",
    "        \"Projet.Code_Decision_ANR\": \"project_id\",\n",
    "        \"Projet.Titre.Francais\": \"title\",\n",
    "        \"Projet.Resume.Francais\": \"abstract\"\n",
    "    }\n",
    ")[[\"project_id\", \"title\", \"abstract\"]]\n",
    "\n",
    "df_anr_clean[\"source\"] = \"anr\"\n",
    "\n",
    "print(\"ANR clean shape:\", df_anr_clean.shape)\n",
    "df_anr_clean.head(2)\n",
    "\n",
    "# Select & rename relevant columns for CORDIS\n",
    "df_cordis_clean = df_cordis.rename(\n",
    "    columns={\n",
    "        \"id\": \"project_id\",\n",
    "        \"title\": \"title\",\n",
    "        \"objective\": \"abstract\"\n",
    "    }\n",
    ")[[\"project_id\", \"title\", \"abstract\"]]\n",
    "\n",
    "df_cordis_clean[\"source\"] = \"cordis\"\n",
    "\n",
    "print(\"CORDIS clean shape:\", df_cordis_clean.shape)\n",
    "df_cordis_clean.head(2)\n",
    "\n",
    "# Merge both datasets\n",
    "df_projects = pd.concat([df_anr_clean, df_cordis_clean], ignore_index=True)\n",
    "\n",
    "print(\"Merged shape:\", df_projects.shape)\n",
    "df_projects.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Classification into Social Sciences & Humanities (SSH)\n",
    "\n",
    "We will now use a pretrained classifier from **SIRIS-Lab** to detect whether each project belongs to the *Social Sciences and Humanities (SSH)* domain.  \n",
    "\n",
    "### Steps:\n",
    "1. **Dataset preparation** — Concatenate title + abstract into a single field  \n",
    "2. **Load the model** — Use Hugging Face `transformers`  \n",
    "3. **Run the classification** — Apply the model to our dataset  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12928</th>\n",
       "      <td>101097433</td>\n",
       "      <td>cordis</td>\n",
       "      <td>Title: Ultimate fracture toughness through thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17267</th>\n",
       "      <td>101110350</td>\n",
       "      <td>cordis</td>\n",
       "      <td>Title: The Drought Impact on the Climate Benef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>101084481</td>\n",
       "      <td>cordis</td>\n",
       "      <td>Title: The ForestWard Observatory to Secure Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17939</th>\n",
       "      <td>101151931</td>\n",
       "      <td>cordis</td>\n",
       "      <td>Title: VIA-TARIQ: Analysing the long-term chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20104</th>\n",
       "      <td>101181208</td>\n",
       "      <td>cordis</td>\n",
       "      <td>Title: MYcotoxin MAnagement (AI)platform To fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      project_id  source                                               text\n",
       "12928  101097433  cordis  Title: Ultimate fracture toughness through thi...\n",
       "17267  101110350  cordis  Title: The Drought Impact on the Climate Benef...\n",
       "10685  101084481  cordis  Title: The ForestWard Observatory to Secure Re...\n",
       "17939  101151931  cordis  Title: VIA-TARIQ: Analysing the long-term chan...\n",
       "20104  101181208  cordis  Title: MYcotoxin MAnagement (AI)platform To fa..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3.1 Dataset preparation\n",
    "df_projects['text'] = (\n",
    "    'Title: ' + df_projects['title'].fillna('').str.strip() +\n",
    "    '\\n\\nAbstract: ' + df_projects['abstract'].fillna('').str.strip()\n",
    ")\n",
    "\n",
    "# drop duplicates\n",
    "df_projects = df_projects.drop(columns=['id','title', 'abstract']).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_projects[['project_id', 'source', 'text']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Step 3.2 Load the model\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TextClassificationPipeline\n",
    ")\n",
    "\n",
    "# ⚠️ IMPORTANT: if the model is private, you must be logged in with your Hugging Face token:\n",
    "#   from huggingface_hub import login\n",
    "#   login(\"YOUR_HF_TOKEN\")\n",
    "\n",
    "model_name = \"SIRIS-Lab/ssh_binary_classifier\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "pipeline_ssh = TextClassificationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    top_k=1,\n",
    "    device=0,      # use GPU if available, else set -1\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>source</th>\n",
       "      <th>ssh</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANR-09-VPTT-0015</td>\n",
       "      <td>anr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANR-09-VPTT-0014</td>\n",
       "      <td>anr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.950545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANR-09-VPTT-0013</td>\n",
       "      <td>anr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANR-09-VPTT-0012</td>\n",
       "      <td>anr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.998463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANR-09-VPTT-0011</td>\n",
       "      <td>anr</td>\n",
       "      <td>False</td>\n",
       "      <td>0.985343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         project_id source    ssh         p\n",
       "0  ANR-09-VPTT-0015    anr  False  0.999436\n",
       "1  ANR-09-VPTT-0014    anr  False  0.950545\n",
       "2  ANR-09-VPTT-0013    anr  False  0.999514\n",
       "3  ANR-09-VPTT-0012    anr  False  0.998463\n",
       "4  ANR-09-VPTT-0011    anr  False  0.985343"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Only include text column\n",
    "dataset = Dataset.from_pandas(df_projects[['text']])\n",
    "\n",
    "# Run the pipeline\n",
    "outputs = []\n",
    "for out in tqdm(pipeline_ssh(KeyDataset(dataset, \"text\"), batch_size=32), total=len(dataset)):\n",
    "    outputs.append(out)\n",
    "\n",
    "# Store results back into df_projects\n",
    "df_projects['ssh'] = [False if o[0]['label'] == 'LABEL_0' else True for o in outputs]\n",
    "df_projects['p'] = [o[0]['score'] for o in outputs]\n",
    "\n",
    "df_projects[['project_id', 'source', 'ssh', 'p']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects['project_id'] = df_projects['project_id'].astype(str)\n",
    "df_projects.to_parquet('../data/analysing_SHS_projects/projects_with_ssh_labels.parquet', index=False, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: ERC Discipline Classification (Multilabel)\n",
    "\n",
    "For the projects classified as SSH, we now assign them to one or more **ERC panels/disciplines** using a pretrained multilabel classifier.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_projects = pd.read_parquet('../data/analysing_SHS_projects/projects_with_ssh_labels.parquet',engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>source</th>\n",
       "      <th>erc_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANR-09-VPTT-0004</td>\n",
       "      <td>anr</td>\n",
       "      <td>[Neuroscience and Disorders of the Nervous Sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANR-09-VILL-0011</td>\n",
       "      <td>anr</td>\n",
       "      <td>[Products and Processes Engineering]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANR-09-VILL-0009</td>\n",
       "      <td>anr</td>\n",
       "      <td>[Earth System Science, Products and Processes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANR-09-VILL-0008</td>\n",
       "      <td>anr</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANR-09-VILL-0006</td>\n",
       "      <td>anr</td>\n",
       "      <td>[Individuals, Markets and Organisations]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         project_id source                                         erc_labels\n",
       "0  ANR-09-VPTT-0004    anr  [Neuroscience and Disorders of the Nervous Sys...\n",
       "1  ANR-09-VILL-0011    anr               [Products and Processes Engineering]\n",
       "2  ANR-09-VILL-0009    anr  [Earth System Science, Products and Processes ...\n",
       "3  ANR-09-VILL-0008    anr                                                 []\n",
       "4  ANR-09-VILL-0006    anr           [Individuals, Markets and Organisations]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "\n",
    "# Step 4.1 Filter SSH projects\n",
    "df_ssh = df_projects[df_projects.ssh].reset_index(drop=True).copy()\n",
    "print(\"SSH projects:\", len(df_ssh))\n",
    "\n",
    "# Step 4.2 Load ERC classifier (multilabel)\n",
    "erc_model_name = \"nicolauduran45/erc_classifier_demo\"\n",
    "\n",
    "erc_tokenizer = AutoTokenizer.from_pretrained(erc_model_name)\n",
    "erc_model = AutoModelForSequenceClassification.from_pretrained(erc_model_name)\n",
    "\n",
    "pipeline_erc = TextClassificationPipeline(\n",
    "    model=erc_model,\n",
    "    tokenizer=erc_tokenizer,\n",
    "    device=0,              # GPU\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_all_scores=True # critical for multilabel\n",
    ")\n",
    "\n",
    "# Step 4.3 Run predictions\n",
    "from datasets import Dataset\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dataset_ssh = Dataset.from_pandas(df_ssh[['text']])\n",
    "\n",
    "outputs = []\n",
    "for out in tqdm(pipeline_erc(KeyDataset(dataset_ssh, \"text\"), batch_size=16), total=len(dataset_ssh)):\n",
    "    outputs.append(out)\n",
    "\n",
    "# Step 4.4 Convert predictions to dataframe columns\n",
    "# Collect labels from model config\n",
    "erc_labels = erc_model.config.id2label.values()\n",
    "\n",
    "# Convert each prediction row into dict {label: score}\n",
    "erc_preds = [\n",
    "    {pred['label']: pred['score'] for pred in row}\n",
    "    for row in outputs\n",
    "]\n",
    "\n",
    "df_erc = pd.DataFrame(erc_preds, index=df_ssh.index)\n",
    "\n",
    "# Join predictions back to main df\n",
    "df_ssh = pd.concat([df_ssh, df_erc], axis=1)\n",
    "\n",
    "# Step 4.5 Decide labels (e.g., threshold 0.5)\n",
    "threshold = 0.5\n",
    "df_ssh['erc_labels'] = df_erc.apply(lambda row: [label for label, score in row.items() if score >= threshold], axis=1)\n",
    "\n",
    "df_ssh[['project_id', 'source', 'erc_labels']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Valorisation Channels Extraction\n",
    "\n",
    "Beyond SSH/discipline classification, we now check whether projects describe **valorisation channels** — i.e. pathways through which research can generate societal or cultural impact.  \n",
    "\n",
    "Based on the literature, we look for the following channels:\n",
    "- Public and academic dissemination  \n",
    "- Policy advice and consultation  \n",
    "- Stakeholder engagement and co-creation  \n",
    "- Citizen science and participatory research  \n",
    "- Education and training initiatives  \n",
    "- Cultural production and advocacy  \n",
    "- Expert services and open licensing  \n",
    "- Institutional and social innovation  \n",
    "\n",
    "We will use a Large Language Model (LLM) API to classify each project description (title + abstract) and return which channels are mentioned.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing model: meta-llama/Llama-3.3-70B-Instruct-Turbo ===\n",
      "Response: - Public and academic dissemination: \n",
      "- Policy advice and consultation: \n",
      "- Stakeholder engagement and co-creation: \"les acteurs de la société civile\"\n",
      "- Citizen science and participatory research: \n",
      "- Education and training initiatives: \n",
      "- Cultural production and advocacy: \n",
      "- Expert services and open licensing: \n",
      "- Institutional and social innovation: \"meilleure structuration de la gouvernance du risque\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from together import Together\n",
    "\n",
    "# --- CONFIG ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"TOGETHER_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"Please set TOGETHER_API_KEY in your .env\")\n",
    "\n",
    "client = Together(api_key=api_key)\n",
    "\n",
    "# List of models to test\n",
    "MODELS = [\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct-Turbo\",\n",
    "]\n",
    "\n",
    "# --- Valorisation channels ---\n",
    "VALORISATION_CHANNELS = [\n",
    "    \"Public and academic dissemination\",\n",
    "    \"Policy advice and consultation\",\n",
    "    \"Stakeholder engagement and co-creation\",\n",
    "    \"Citizen science and participatory research\",\n",
    "    \"Education and training initiatives\",\n",
    "    \"Cultural production and advocacy\",\n",
    "    \"Expert services and open licensing\",\n",
    "    \"Institutional and social innovation\"\n",
    "]\n",
    "\n",
    "# --- Prompt builder ---\n",
    "def build_prompt(channels, text):\n",
    "    return f\"\"\"You are a scientific tagger.\n",
    "\n",
    "Goal:\n",
    "Identify mentions of knowledge valorisation channels described in the project text.\n",
    "\n",
    "Channels to check:\n",
    "{channels}\n",
    "\n",
    "Project text:\n",
    "{text}\n",
    "\n",
    "Output format:\n",
    "- For each channel, output a bullet point in the form:\n",
    "  - <Channel Label>: \"<verbatim mention from the text>\"\n",
    "- If multiple mentions exist for the same channel, include multiple bullets (one per mention).\n",
    "- If a channel is not mentioned at all, output it with no quotes.\n",
    "\n",
    "Example:\n",
    "- Public and academic dissemination: \"publiation of conference proceedings\"\n",
    "- Public and academic dissemination: \"journal article\"\n",
    "- Policy advice and consultation: \"consultancy to the European Commission in the climate policies\n",
    "- Stakeholder engagement and co-creation: \"organisation of stakeholder workshops with local actors\"\n",
    "\n",
    "Rules:\n",
    "1. Use verbatim spans from the input text (no paraphrasing, no translation).\n",
    "2. If ambiguous/generic terms appear, include them only if clearly tied to the channel by context.\n",
    "3. Do not add explanations, headers, or prose — only the bullet points.\n",
    "4. Return in English, even if the input text is in another language.\n",
    "\"\"\"\n",
    "\n",
    "# --- Test with a single project ---\n",
    "id = 50\n",
    "text = df_ssh.loc[id, \"text\"]\n",
    "\n",
    "TEST_PROMPT = build_prompt(VALORISATION_CHANNELS, text)\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "for model_name in MODELS:\n",
    "    print(f\"\\n=== Testing model: {model_name} ===\")\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": TEST_PROMPT}],\n",
    "            temperature=0,\n",
    "            stop=[\"<|eot_id|>\", \"<|eom_id|>\"],  # optional, helps truncate\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "        print(\"Response:\", output, \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error with model {model_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"font-family:Arial, sans-serif; line-height:1.5;\">\n",
       "      <div><b style=\"color:darkblue;\">Title:</b> Etudes Multidisciplinaires du Mouvement de Séchilienne : aléa, risques associés et conséquences socio-économiques</div>\n",
       "      <div style=\"margin-top:10px;\"><b style=\"color:darkgreen;\">Abstract:</b> Les mouvements de terrain de grande ampleur ont un impact socio-économique qui peut s?avérer dramatique. Les mécanismes contrôlant leur dynamique ou leur déclenchement sont nombreux et complexes, ce qui entraîne une forte incertitude dans la prévision que ce soit dans le domaine spatial (volume mis en jeu, localisation) ou temporel (occurrence, dynamique). Ceci provoque un important décalage entre la communauté scientifique, les gestionnaires du risque et <mark style='background-color:#9999ff'>les acteurs de la société civile</mark><sub><b style='color:#9999ff'>Stakeholder engagement and co-creation</b></sub>, car la gestion des incertitudes est abordée selon des protocoles très divers, propres aux acteurs impliqués et à leur responsabilité. Le présent projet se propose de les fédérer sur un site sensible, le mouvement de terrain de Séchilienne. En effet, en France métropolitaine, celui-ci constitue probablement le phénomène naturel présentant potentiellement le plus fort risque combiné en termes de conséquences socio-économiques. Ce site est un exemple emblématique des questions épineuses soulevées depuis 25 ans de gestion administrative, scientifique et politique, notamment en raison de sa dimension pluridisciplinaire. L’investissement sociétal considérable effectué au cours de ces années a privilégié la gestion du risque. A l’inverse, ce site a souffert du manque de projets de recherche fondamentale véritablement interdisciplinaires. Nous proposons donc un projet ambitieux qui vise à étudier non seulement l’aléa mais aussi la vulnérabilité organisationnelle, pour proposer une <mark style='background-color:#66b3ff'>meilleure structuration de la gouvernance du risque</mark><sub><b style='color:#66b3ff'>Institutional and social innovation</b></sub>. Au niveau de l’aléa, nous proposons une approche multidisciplinaire reposant sur le système de surveillance actuel et sur l’acquisition de nouvelles données. Ces données serviront de base d’entrée à différents types de modélisations numériques qui viseront à reproduire la dynamique passée et actuelle. Cet ensemble de travaux servira de porte d’entrée à la constitution d’un arbre de décision interdisciplinaire prenant en compte les incertitudes.</div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-top:10px;'><b>Predicted ERC labels:</b> <b style='color:orange'>Individuals, Markets and Organisations</b>, <b style='color:orange'>The Social World and Its Interactions</b></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# --- Highlighter for valorisation spans ---\n",
    "def highlight_entities_html(title, abstract, entities):\n",
    "    # Sort entities by start\n",
    "    entities = sorted(entities, key=lambda e: e['start'])\n",
    "    out, last_idx = \"\", 0\n",
    "\n",
    "    # fixed palette\n",
    "    palette = {\n",
    "        \"Public and academic dissemination\": \"#ff9999\",\n",
    "        \"Policy advice and consultation\": \"#99ff99\",\n",
    "        \"Stakeholder engagement and co-creation\": \"#9999ff\",\n",
    "        \"Citizen science and participatory research\": \"#ffcc99\",\n",
    "        \"Education and training initiatives\": \"#cc99ff\",\n",
    "        \"Cultural production and advocacy\": \"#99ffff\",\n",
    "        \"Expert services and open licensing\": \"#ffb366\",\n",
    "        \"Institutional and social innovation\": \"#66b3ff\"\n",
    "    }\n",
    "\n",
    "    # Build highlighted abstract\n",
    "    highlighted = \"\"\n",
    "    last_idx = 0\n",
    "    for ent in entities:\n",
    "        start, end, label = ent[\"start\"], ent[\"end\"], ent[\"label\"]\n",
    "        highlighted += abstract[last_idx:start]\n",
    "        color = palette.get(label, \"#dddddd\")\n",
    "        span = (\n",
    "            f\"<mark style='background-color:{color}'>{abstract[start:end]}\"\n",
    "            f\"</mark><sub><b style='color:{color}'>{label}</b></sub>\"\n",
    "        )\n",
    "        highlighted += span\n",
    "        last_idx = end\n",
    "    highlighted += abstract[last_idx:]\n",
    "\n",
    "    # Add title + abstract sections with color headings\n",
    "    html = f\"\"\"\n",
    "    <div style=\"font-family:Arial, sans-serif; line-height:1.5;\">\n",
    "      <div><b style=\"color:darkblue;\">Title:</b> {title}</div>\n",
    "      <div style=\"margin-top:10px;\"><b style=\"color:darkgreen;\">Abstract:</b> {highlighted}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return html\n",
    "\n",
    "# --- Parser for bullet outputs ---\n",
    "def parse_valorisation_output(output_text):\n",
    "    entities = []\n",
    "    for line in output_text.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line.startswith(\"-\"):\n",
    "            continue\n",
    "        match = re.match(r'-\\s*(.*?):\\s*\"(.*)\"', line)\n",
    "        if match:\n",
    "            label, mention = match.groups()\n",
    "            entities.append({\"label\": label.strip(), \"mention\": mention.strip()})\n",
    "    return entities\n",
    "\n",
    "# --- Expand mentions into spans ---\n",
    "def mentions_to_entities(text, mentions):\n",
    "    entities = []\n",
    "    for m in mentions:\n",
    "        label, mention = m[\"label\"], m[\"mention\"]\n",
    "        for match in re.finditer(re.escape(mention), text):\n",
    "            entities.append({\"label\": label, \"start\": match.start(), \"end\": match.end()})\n",
    "    return entities\n",
    "\n",
    "# --- Example usage ---\n",
    "title = df_ssh.loc[id, \"title\"]\n",
    "abstract = df_ssh.loc[id, \"abstract\"]\n",
    "model_output = output  # text returned by model\n",
    "\n",
    "# Parse model output → mentions\n",
    "mentions = parse_valorisation_output(model_output)\n",
    "\n",
    "# Convert mentions → spans (on abstract only)\n",
    "entities = mentions_to_entities(abstract, mentions)\n",
    "\n",
    "# Highlight Title + Abstract\n",
    "display(HTML(highlight_entities_html(title, abstract, entities)))\n",
    "\n",
    "# Print ERC labels\n",
    "pred_labels_html = ', '.join([\n",
    "    f\"<b style='color:orange'>{label}</b>\"\n",
    "    for label in df_ssh.loc[id, 'erc_labels']\n",
    "])\n",
    "erc_html = f\"<div style='margin-top:10px;'><b>Predicted ERC labels:</b> {pred_labels_html}</div>\"\n",
    "display(HTML(erc_html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5708"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meloner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
